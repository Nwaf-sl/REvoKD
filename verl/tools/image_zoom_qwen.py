import logging
import os
import threading
from contextlib import ExitStack
from enum import Enum
from math import ceil, floor
from typing import Any, Callable, Optional, TypeVar
from uuid import uuid4

import ray
import ray.actor
from qwen_vl_utils import fetch_image

from .base_tool import BaseTool
from .schemas import OpenAIFunctionToolSchema, ToolResponse

logger = logging.getLogger(__name__)
logger.setLevel(os.getenv("VERL_LOGGING_LEVEL", "WARN"))

T = TypeVar("T")


class PoolMode(Enum):
    """Execution pool mode enumeration."""
    ThreadMode = 1
    ProcessMode = 2


@ray.remote(concurrency_groups={"acquire": 1, "release": 10})
class TokenBucketWorker:
    """Ray actor for rate limiting using token bucket algorithm."""
    def __init__(self, rate_limit: int):
        self.rate_limit = rate_limit
        self.current_count = 0
        self._semaphore = threading.Semaphore(rate_limit)

    @ray.method(concurrency_group="acquire")
    def acquire(self):
        self._semaphore.acquire()
        self.current_count += 1

    @ray.method(concurrency_group="release")
    def release(self):
        self._semaphore.release()
        self.current_count -= 1

    def get_current_count(self):
        return self.current_count


class VisualExecutionWorker:
    """Worker for executing visual processing operations with optional rate limiting."""
    def __init__(self, enable_global_rate_limit=True, rate_limit=10):
        self.rate_limit_worker = self._init_rate_limit(rate_limit) if enable_global_rate_limit else None

    def _init_rate_limit(self, rate_limit):
        return TokenBucketWorker.options(name="rate-limiter", get_if_exists=True).remote(rate_limit)

    def ping(self):
        return True

    def execute(self, fn: Callable[..., T], *fn_args, **fn_kwargs) -> T:
        if self.rate_limit_worker:
            with ExitStack() as stack:
                stack.callback(self.rate_limit_worker.release.remote)
                ray.get(self.rate_limit_worker.acquire.remote())
                try:
                    return fn(*fn_args, **fn_kwargs)
                except Exception as e:
                    logger.warning(f"Error when executing visual processing: {e}")
        else:
            return fn(*fn_args, **fn_kwargs)


def init_visual_execution_pool(
    num_workers: int, enable_global_rate_limit=True, rate_limit=10,
    mode: PoolMode = PoolMode.ThreadMode
):
    if mode == PoolMode.ThreadMode:
        return (
            ray.remote(VisualExecutionWorker)
            .options(max_concurrency=num_workers)
            .remote(enable_global_rate_limit=enable_global_rate_limit, rate_limit=rate_limit)
        )
    else:
        raise NotImplementedError("Process mode is not implemented yet")


class ImageZoomInTool(BaseTool):
    """RLHF训练版 ImageZoomInTool，已适配Qwen Agent的参数schema。"""

    MIN_DIMENSION = 28

    # def __init__(self, config: dict):
    # def __init__(self, config: dict, tool_schema: OpenAIFunctionToolSchema = None):
    #     # ✅ 这里直接改成 Qwen Agent 的 schema
    #     # if tool_schema is None:
    #     #             tool_schema = OpenAIFunctionToolSchema.model_validate({
    #     #                 "type": "function",
    #     #                 "function": {
    #     #                     "name": "image_zoom_in_tool",
    #     #                     "description": "Zoom in on a specific region of an image...",
    #     #                     "parameters": {
    #     #                         "type": "object",
    #     #                         "properties": {
    #     #                             "bbox_2d": {
    #     #                                 "type": "array",
    #     #                                 "items": {"type": "number"},
    #     #                                 "minItems": 4,
    #     #                                 "maxItems": 4,
    #     #                                 "description": (
    #     #                                     "Bounding box as [x1,y1,x2,y2] in relative coords (0~1000)"
    #     #                                 ),
    #     #                             },
    #     #                             "label": {"type": "string"},
    #     #                             "img_idx": {"type": "number"}
    #     #                         },
    #     #                         "required": ["bbox_2d", "label", "img_idx"],
    #     #                     }
    #     #                 }
    #     #             })

    #     super().__init__(config, tool_schema)
    #     self._instance_dict = {}
    #     self.num_workers = config.get("num_workers", 20)
    #     self.rate_limit = config.get("rate_limit", 50)
    #     self.timeout = config.get("timeout", 30)
    #     self.enable_global_rate_limit = config.get("enable_global_rate_limit", True)
    #     self.execution_pool = init_visual_execution_pool(
    #         num_workers=self.num_workers,
    #         enable_global_rate_limit=self.enable_global_rate_limit,
    #         rate_limit=self.rate_limit,
    #         mode=PoolMode.ThreadMode,
    #     )
    #     logger.info(f"Initialized ImageZoomInTool with config: {config}")
    def __init__(self, config: dict, tool_schema: Optional[dict | OpenAIFunctionToolSchema] = None):
    # 如果没有传 tool_schema 或者传的是 dict，就用默认的 Qwen Agent 风格 schema
        if not isinstance(tool_schema, OpenAIFunctionToolSchema):
            tool_schema = OpenAIFunctionToolSchema.model_validate(tool_schema or {
                "type": "function",
                "function": {
                    "name": "image_zoom_in_tool",
                    "description": (
                        "Zoom in on a specific region of an image by cropping it "
                        "based on a bounding box (bbox) and an optional label."
                    ),
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "bbox_2d": {
                                "type": "array",
                                "items": {"type": "number"},
                                "minItems": 4,
                                "maxItems": 4,
                                "description": (
                                    "Bounding box as [x1,y1,x2,y2] in relative coords (0~1000), "
                                    "where (x1,y1) is top-left and (x2,y2) is bottom-right."
                                ),
                            },
                            "label": {
                                "type": "string",
                                "description": "Optional label of object inside the bounding box."
                            },
                            "img_idx": {
                                "type": "number",
                                "description": "Index of the image to zoom in (starting from 0)."
                            }
                        },
                        # 保证 required 列表和 properties 一致，避免注册失败
                        "required": ["bbox_2d", "label", "img_idx"]
                    }
                }
            })

        super().__init__(config, tool_schema)

        self._instance_dict = {}
        self.num_workers = config.get("num_workers", 20)
        self.rate_limit = config.get("rate_limit", 50)
        self.timeout = config.get("timeout", 30)
        self.enable_global_rate_limit = config.get("enable_global_rate_limit", True)
        self.execution_pool = init_visual_execution_pool(
            num_workers=self.num_workers,
            enable_global_rate_limit=self.enable_global_rate_limit,
            rate_limit=self.rate_limit,
            mode=PoolMode.ThreadMode,
        )
        # 延迟初始化执行池，减少启动压力
        # self.execution_pool = None
        logger.info(f"Initialized ImageZoomInTool with config: {config}")
       

    # def _ensure_execution_pool(self):
    #     """延迟初始化执行池"""
    #     if self.execution_pool is None:
    #         self.execution_pool = init_visual_execution_pool(
    #             num_workers=self.num_workers,
    #             enable_global_rate_limit=self.enable_global_rate_limit,
    #             rate_limit=self.rate_limit,
    #             mode=PoolMode.ThreadMode,
    #         )
    def _validate_bbox(self, left: float, top: float, right: float, bottom: float) -> bool:
        try:
            if not (left < right and top < bottom):
                return False
            height = bottom - top
            width = right - left
            if min(height, width) == 0:
                return False
            if max(height, width) / min(height, width) > 100:
                return False
            return True
        except Exception:
            return False

    def _maybe_resize_bbox(self, bbox_2d: list[float], image_width: int, image_height: int) -> Optional[list[float]]:
        left, top, right, bottom = bbox_2d
        left = max(0.0, float(left))
        top = max(0.0, float(top))
        right = min(float(image_width), float(right))
        bottom = min(float(image_height), float(bottom))
        if not self._validate_bbox(left, top, right, bottom):
            return None
        current_bbox = [left, top, right, bottom]
        height = bottom - top
        width = right - left
        if height < self.MIN_DIMENSION or width < self.MIN_DIMENSION:
            center_x = (left + right) / 2.0
            center_y = (top + bottom) / 2.0
            min_dim = min(height, width)
            if min_dim == 0:
                return None
            ratio = self.MIN_DIMENSION / min_dim
            target_width = width * ratio
            target_height = height * ratio
            if target_width > image_width:
                scale_down = image_width / target_width
                target_width = image_width
                target_height *= scale_down
            if target_height > image_height:
                scale_down = image_height / target_height
                target_height = image_height
                target_width *= scale_down
            new_half_width = target_width / 2.0
            new_half_height = target_height / 2.0
            new_left = max(0, center_x - new_half_width)
            new_top = max(0, center_y - new_half_height)
            if new_left + target_width > image_width:
                new_left = image_width - target_width
            if new_top + target_height > image_height:
                new_top = image_height - target_height
            new_right = new_left + target_width
            new_bottom = new_top + target_height
            current_bbox = [floor(new_left), floor(new_top), ceil(new_right), ceil(new_bottom)]
        final_left, final_top, final_right, final_bottom = current_bbox
        if not self._validate_bbox(final_left, final_top, final_right, final_bottom):
            return None
        if (final_bottom - final_top) < self.MIN_DIMENSION or (final_right - final_left) < self.MIN_DIMENSION:
            return None
        return current_bbox

    def get_openai_tool_schema(self) -> OpenAIFunctionToolSchema:
        return self.tool_schema

    async def create(self, instance_id: Optional[str] = None, **kwargs) -> tuple[str, ToolResponse]:
        if instance_id is None:
            instance_id = str(uuid4())
        create_kwargs = kwargs.get("create_kwargs", {})
        if create_kwargs:
            kwargs.update(create_kwargs)
        image = kwargs.get("image")
        if image is None:
            raise ValueError("Missing required 'image' parameter in kwargs")
        img = fetch_image({"image": image})
        self._instance_dict[instance_id] = {
            "image": img,
            "response": "",
            "reward": 0.0,
        }
        return instance_id, ToolResponse()

    async def execute(self, instance_id: str, parameters: dict[str, Any], **kwargs) -> tuple[ToolResponse, float, dict]:
        bbox_2d = parameters.get("bbox_2d")
        label = parameters.get("label", "")
        img_idx = parameters.get("img_idx", 0)

        if not bbox_2d or len(bbox_2d) != 4:
            logger.warning(f"bbox_2d invalid: value={bbox_2d}, type={type(bbox_2d)}")
            return ToolResponse(text="Error: bbox_2d parameter is missing or not a list of 4 numbers."), -0.2, {"success": False}

        instance_data = self._instance_dict[instance_id]
        image = instance_data["image"]
        image_width, image_height = image.size

        # ✅ 把比例坐标转成像素坐标
        abs_bbox = [
            bbox_2d[0] / 1000.0 * image_width,
            bbox_2d[1] / 1000.0 * image_height,
            bbox_2d[2] / 1000.0 * image_width,
            bbox_2d[3] / 1000.0 * image_height,
        ]

        try:
            resized_bbox = self._maybe_resize_bbox(abs_bbox, image_width, image_height)
            if resized_bbox is None:
                return ToolResponse(text="Error: bbox invalid or too small."), -0.05, {"success": False}
            cropped_image = image.crop(resized_bbox)
        except Exception as e:
            return ToolResponse(text=f"Error processing image zoom-in: {e}"), -0.05, {"success": False}

        response_text = f"Zoomed on region {bbox_2d} (label={label})"
        # print(response_text)
        # breakpoint()
        return ToolResponse(image=[cropped_image], text=response_text), 0.0, {"success": True}

    async def release(self, instance_id: str, **kwargs) -> None:
        if instance_id in self._instance_dict:
            del self._instance_dict[instance_id]
